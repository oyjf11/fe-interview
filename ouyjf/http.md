- 1
    - [请说说你对http中keep-alive的理解](https://github.com/haizlin/fe-interview/issues/5074)

    - http的keep-alive是干什么的？
        在早期–http1.0的协议都是建立在TCP协议基础上，其特点就是传输完数据后，立马就释放掉该TCP链接，也就是短连接。
        随着技术的发展，一个网页需要建立很多次短连接，这大大影响了消息的处理，所以http就提出了持续连接的概念，也就是让连接保存一段时间，后续的http消息可以复用这个连接继续传输消息，也就是Keep-Alive模式。
        当使用Keep-Alive模式（又称持久连接、连接重用）时，Keep-Alive功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive功能避免了建立或者重新建立连接。
        备注：持久连接的主要好处是避免了短连接的每次连接的三次握手和四次挥手的网络交互。

    - http的keep-alive如何使用？
        在http协议的Header头，有两个Tag可以控制这个keep-alive，Connection: Keep-Alive 和 Keep-Alive:timeout，它们表示的是保持持续连接状态的时间为timeout秒。
        http 1.0中默认是关闭的，需要在http头加入"Connection: Keep-Alive"，才能启用Keep-Alive；
        http 1.1中默认启用Keep-Alive，如果加入"Connection: close "，才关闭。
        目前大部分浏览器都是用http1.1协议，也就是说默认都会发起Keep-Alive的连接请求了，所以是否能完成一个完整的Keep-Alive连接就看服务器设置情况。

    - http如何区分多个请求, 如何知道当前请求已经结束？
        Content-Length
            当浏览器请求的是一个静态资源时，即服务器能明确知道返回内容的长度时，可以设置Content-Length来控制请求的结束
        Transfer-Encoding
            表示传输编码。
            还有一个类似的字段叫做：Content-Encoding。区别是Content-Encoding用于对实体内容的压缩编码（Content-Encoding: gzip）； Transfer-Encoding则改变了报文的格式。
            当服务端无法知道实体内容的长度时，可指定Transfer-Encoding:chunked (还可同时指定Transfer-Encoding: gzip)，表明实体内容数据不仅是gzip压缩的，还是分块传递的。最终当浏览器接收到一个长度为0的chunked时， 标识当前请求内容已全部接收。

    -   Keep-Alive的建立过程：
        ● 客户端向服务器在发送请求报文同时在首部添加发送Connection字段
        ● 服务器收到请求并处理 Connection字段
        ● 服务器回送Connection:Keep-Alive字段给客户端
        ● 客户端接收到Connection字段
        ● Keep-Alive连接建立成功

    -   服务端自动断开过程（也就是没有keep-alive）：
        ● 客户端向服务器只是发送内容报文（不包含Connection字段）
        ● 服务器收到请求并处理
        ● 服务器返回客户端请求的资源并关闭连接
        ● 客户端接收资源，发现没有Connection字段，断开连接

    -   客户端请求断开连接过程：
        ● 客户端向服务器发送Connection:close字段
        ● 服务器收到请求并处理connection字段
        ● 服务器回送响应资源并断开连接
        ● 客户端接收资源并断开连接
    
    -   开启Keep-Alive的优点：
        ● 较少的CPU和内存的使⽤（由于同时打开的连接的减少了）；
        ● 允许请求和应答的HTTP管线化；
        ● 降低拥塞控制 （TCP连接减少了）；
        ● 减少了后续请求的延迟（⽆需再进⾏握⼿）；
        ● 报告错误⽆需关闭TCP连；

    -   开启Keep-Alive的缺点：

        ● 长时间的Tcp连接容易导致系统资源无效占用，浪费系统资源。

- 2
    - [HTTP 2.0]()

    -   二进制协议：
        HTTP/2 是一个二进制协议。
        在 HTTP/1.1 版中，报文的头信息必须是文本（ASCII 编码），数据体可以是文本，也可以是二进制。
        HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"，可以分为头信息帧和数据帧。 
        帧的概念是它实现多路复用的基础。
    
    -   多路复用：
        HTTP/2 实现了多路复用，HTTP/2 仍然复用 TCP 连接，但是在一个连接里，客户端和服务器都可以同时发送多个请求或回应，而且不用按照顺序一一发送，这样就避免了"队头堵塞"【1】的问题。

    -   数据流：
        HTTP/2 使用了数据流的概念，因为 HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的请求。
        因此，必须要对数据包做标记，指出它属于哪个请求。
        HTTP/2 将每个请求或回应的所有数据包，称为一个数据流。
        每个数据流都有一个独一无二的编号。数据包发送时，都必须标记数据流 ID ，用来区分它属于哪个数据流。

    -   头信息压缩：
        HTTP/2 实现了头信息压缩，由于 HTTP 1.1 协议不带状态，每次请求都必须附上所有信息。
        所以，请求的很多字段都是重复的，比如 Cookie 和 User Agent ，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。
        HTTP/2 对这一点做了优化，引入了头信息压缩机制。
        一方面，头信息使用 gzip 或 compress 压缩后再发送；
        另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就能提高速度了。

    -   服务器推送：
        HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送。
        使用服务器推送提前给客户端推送必要的资源，这样就可以相对减少一些延迟时间。
        这里需要注意的是 http2 下服务器主动推送的是静态资源，和 WebSocket 以及使用 SSE 等方式向客户端发送即时数据的推送是不同的。

- 3
    - [对头阻塞]()

    -   队头阻塞是由 HTTP 基本的“请求 - 应答”模型所导致的。
        HTTP 规定报文必须是“一发一收”，这就形成了一个先进先出的“串行”队列。
        队列里的请求是没有优先级的，只有入队的先后顺序，排在最前面的请求会被最优先处理。
        如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得不跟着一起等待，结果就是其他的请求承担了不应有的时间成本，造成了队头堵塞的现象。